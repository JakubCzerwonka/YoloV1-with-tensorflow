{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 17:22:19.411545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762705339.431909    6903 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762705339.438225    6903 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762705339.453231    6903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762705339.453256    6903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762705339.453258    6903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762705339.453260    6903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-09 17:22:19.458547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from yolo_loss import YoloLoss\n",
    "from yolo_model import yolo_v1_model\n",
    "from yolo_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf9e82",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06854d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (448, 448)\n",
    "S, B, C = 7, 2, 20\n",
    "\n",
    "model = yolo_v1_model(img_size=(img_size[0], img_size[1], 3), S=S, B=B, C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524901d",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef669c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET_TRAIN = \"/VOCtrainval_06-Nov-2007/VOCdevkit/VOC2007/Annotations/\"\n",
    "\n",
    "files = [os.path.join(PATH_DATASET_TRAIN, f) for f in sorted(os.listdir(PATH_DATASET_TRAIN)) if f.endswith(\".xml\")]\n",
    "train_files, valid_files = train_test_split(files, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Removing classes head, hand, foot like in orginal paper\n",
    "class_names = [\"person\", \"bird\", \"cat\", \"cow\", \"dog\", \"horse\", \"sheep\", \"aeroplane\", \"bicycle\", \"boat\", \"bus\", \"car\", \"motorbike\", \"train\", \"bottle\", \"chair\", \"diningtable\", \"pottedplant\", \"sofa\", \"tvmonitor\", \"head\", \"foot\", \"hand\"]\n",
    "remove_those_vals = ['head', 'hand', 'foot']\n",
    "\n",
    "batch_size = 32\n",
    "train_gen = DataGenerator(train_files, img_size, class_names, remove_those_vals, S=S, B=B, C=C, batch_size=batch_size, shuffle=True, augment=True)\n",
    "valid_gen = DataGenerator(valid_files, img_size, class_names, remove_those_vals, S=S, B=B, C=C, shuffle=True, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c390dc9",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d80304",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkPointCallback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './weights/weights.keras',\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\",\n",
    "    initial_value_threshold=None,\n",
    ")\n",
    "\n",
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.001,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c615b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = YoloLoss(S=S, B=B, C=C, lambda_coord=5.0, lambda_noobj=0.5)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf420b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    validation_data=valid_gen, \n",
    "                    epochs=epochs,\n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[ReduceLROnPlateau, checkPointCallback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b59a2",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_to_plot = 10\n",
    "PATH_DATASET_TEST = \"/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/Annotations/\"\n",
    "\n",
    "X_test, y_boxes_test, y_labels_test = load_dataset(PATH_DATASET_TEST, remove_those_vals, image_target_size=img_size, n_img=n_images_to_plot)\n",
    "X_test, y_boxes_test, y_labels_test = shuffle(X_test, y_boxes_test, y_labels_test)\n",
    "\n",
    "X_test_preprocess = preprocess_input(np.array(X_test))\n",
    "y_test_labels_onehot = to_one_hot(y_labels_test, class_names)\n",
    "\n",
    "y_boxes_test_normalized = xywh_pixels_to_normalized_centers_per_image(y_boxes_test, img_size)\n",
    "\n",
    "for i in range(len(y_boxes_test_normalized)):\n",
    "    y_boxes_test_normalized[i] = np.array(y_boxes_test_normalized[i]).reshape(-1, 4)\n",
    "\n",
    "# For validate encode & decode functions\n",
    "y_test_encoded = encode_batch(y_boxes_test_normalized, y_test_labels_onehot, S=S, B=B, C=C)\n",
    "y_test_decoded = decode_batch(y_test_encoded, S=S, B=B, img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_preprocess, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93128628",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test[:n_images_to_plot], training=False).numpy()\n",
    "\n",
    "y_pred_decoded = decode_batch(y_pred, S=S, B=B, img_size=img_size, conf_thresh=0.5)\n",
    "print(\"Detections per image:\", [len(r) for r in y_pred_decoded][:n_images_to_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178dd1b8",
   "metadata": {},
   "source": [
    "Non Maximum Suppresion can be implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_and_box(X, y_boxes, y_pred_boxes=False, n_images=1, figsize=(10, 10)):\n",
    "\n",
    "    fig, ax = plt.subplots(n_images, 2, figsize=(figsize[0], figsize[1]  * n_images))\n",
    "\n",
    "    if n_images == 1:\n",
    "        ax = np.array([ax])\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax[i, 0].imshow(X[i])\n",
    "        ax[i, 1].imshow(X[i])\n",
    "\n",
    "        # True boxes and labels\n",
    "        for j in range(len(y_boxes[i])):\n",
    "\n",
    "            # Boxes\n",
    "            box_1 = np.array(y_boxes[i][j])\n",
    "            x, y, w, h = box_1[0], box_1[1], box_1[2], box_1[3]\n",
    "            rect =  patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='blue', facecolor='none', label='true')    \n",
    "            ax[i, 0].add_patch(rect)\n",
    "\n",
    "            # Labels and confs\n",
    "            conf, label = box_1[4], box_1[5]\n",
    "            label_text = class_names[int(label)]\n",
    "            ax[i, 0].text(x, y -5, f\"{label_text} ({conf:.2f})\", color='black', fontsize=9, backgroundcolor='white')\n",
    "            ax[i, 0].axis('off')\n",
    "\n",
    "        # Pred boxes and labels\n",
    "        for j in range(len(y_pred_boxes[i])):\n",
    "            # Boxes\n",
    "            box_2 = np.array(y_pred_boxes[i][j])\n",
    "            x, y, w, h = box_2[0], box_2[1], box_2[2], box_2[3]\n",
    "            rect =  patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='blue', facecolor='none', label='true')    \n",
    "            ax[i, 1].add_patch(rect)\n",
    "\n",
    "            # Labels and confs\n",
    "            conf, label = box_2[4], box_2[5]\n",
    "            label_text = class_names[int(label)]\n",
    "            ax[i, 1].text(x, y -5, f\"{label_text} ({conf:.2f})\", color='black', fontsize=9, backgroundcolor='white')\n",
    "            ax[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout(pad=0.1)\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.02, top=0.59, bottom=0.01)\n",
    "    plt.show()\n",
    "\n",
    "plot_img_and_box(X_test, y_test_decoded, y_pred_decoded, n_images=n_images_to_plot, figsize=(6, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
